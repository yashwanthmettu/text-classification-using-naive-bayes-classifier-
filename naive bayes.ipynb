{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94378bd6-3a16-4d60-903d-f66e5b07f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb9baad-7880-4a8c-8338-8906daa6f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data='20_newsgroups'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd491a0-fe30-4fa1-b7c8-416dec6a897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories= os.listdir(os.path.join(os.getcwd(),data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a88ff7-4eee-41f7-8438-f4c399f90b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1779fa4d-6ecc-4462-93dc-d7cf71cf9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0351bfee-3a26-4713-a14d-8c6408224fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "data_dict={}\n",
    "for type in categories:\n",
    "    data_dict[type]=[]\n",
    "    for file in os.listdir(os.path.join(data,type)):\n",
    "         with open(os.path.join(data,type,file),encoding='latin-1') as opened_file:\n",
    "            data_dict[type].append(opened_file.read())\n",
    "print(len(data_dict[categories[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb488383-0b35-482e-8ff4-64f7d8c2f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders=[i for i in os.listdir(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1214141a-1342-4825-a669-3d006df950c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for name in folders:\n",
    "    path = os.path.join(data, name)\n",
    "    files.append([f for f in os.listdir(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5528e9b1-1b60-4e21-adc9-a2f0395671b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "for fo in range(len(folders)):\n",
    "    for fi in files[fo]:\n",
    "        x.append(os.path.join(data, os.path.join(folders[fo], fi)))\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0055bd-25f7-43f5-9872-1033fc505dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for name in folders:\n",
    "    path = os.path.join(data, name)\n",
    "    num_of_files= len(os.listdir(path))\n",
    "    for i in range(num_of_files):\n",
    "        y.append(name)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96a1063-78dc-4d3d-b86c-7fefbaa23e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd7d214-6301-48fd-96f9-9ed08a89cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5131d069-4414-40cc-940e-371c2586cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    punctuations = set(punctuation)\n",
    "    stop_words.update(punctuations)\n",
    "    stop_words.add('subject')  \n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word.lower()) for word in tokens if word.lower() not in stop_words]\n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dcc791f-1e21-4771-95e2-1fb30ed6c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbf4f74-3829-4fb5-b1e0-d95908d7454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenize(line):\n",
    "    from nltk import word_tokenize\n",
    "    tokens = word_tokenize(line)\n",
    "    tokens = preprocessing(tokens)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb89f977-819d-43a6-bd8a-5bc2b313b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_metadata(lines):\n",
    "    for i in range(len(lines)):\n",
    "        if(lines[i] == '\\n'):\n",
    "            start = i+1\n",
    "            break\n",
    "    return lines[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "531fc808-7bb9-4937-9230-387019f5acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preprocess(path):\n",
    "    with open(path, 'r') as f:\n",
    "        text_lines = f.readlines()\n",
    "        text_lines = remove_metadata(text_lines)\n",
    "        doc_words = [preprocessing(line) for line in text_lines]\n",
    "    return doc_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "517a6d1c-9820-4047-b23f-23ddc8975103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst):\n",
    "    flatten_list = [j for i in lst for j in i]\n",
    "    return flatten_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12b94c66-164a-4424-b420-379c969f8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens = []\n",
    "\n",
    "for document in x_train:\n",
    "        X_tokens.append(flatten(tokenize_and_preprocess(document)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cec2f7c-14d0-47db-ab80-91088ec0d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_X_tokens = np.asarray(flatten(X_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fc2ea49-eb9c-4371-bf21-d52b889bd86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120120"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, counts = np.unique(np_X_tokens, return_counts=True)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ba3713d-2f3d-4174-ac64-a0bfc440d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, wrds = (list(i) for i in zip(*(sorted(zip(counts, words), reverse=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd1885e7-f7f9-4153-9e1b-81540af9db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = []\n",
    "no_words = []\n",
    "for f in sorted(np.unique(freq), reverse=True):\n",
    "    freq_words.append(f)\n",
    "    no_words.append(freq.count(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fefc2838-c700-45e3-8ff8-ce7c68d3edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5000\n",
    "features=wrds[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7a1544e-2c8b-4acc-8b1e-10535c5f357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_train = {}\n",
    "doc_num = 1\n",
    "for doc_words in X_tokens:\n",
    "    dictionary_train[doc_num]={}\n",
    "    for word in doc_words:\n",
    "        if word in dictionary_train[doc_num]:\n",
    "            dictionary_train[doc_num][word]+=1\n",
    "        else:\n",
    "            dictionary_train[doc_num][word]=1\n",
    "    doc_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7679132e-6192-44f0-b298-dbef2d552fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for k in dictionary_train.keys():\n",
    "    row = []\n",
    "    for f in features:\n",
    "        if(f in dictionary_train[k].keys()):\n",
    "            row.append(dictionary_train[k][f]) \n",
    "        else:\n",
    "            row.append(0)\n",
    "    X_train.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "743b593b-da15-484c-9fba-c77fc76a935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1649c864-eee2-4c28-87d3-2b9af4e2981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tokens = []\n",
    "for document in x_test:\n",
    "        Y_tokens.append(flatten(tokenize_and_preprocess(document)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "265ed7d9-27a5-4bd7-b0a6-2ee48824fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_test = {}\n",
    "doc_num = 1\n",
    "for doc_words in Y_tokens:\n",
    "    dictionary_test[doc_num]={}\n",
    "    for word in doc_words:\n",
    "        if word in dictionary_test[doc_num]:\n",
    "            dictionary_test[doc_num][word]+=1\n",
    "        else:\n",
    "            dictionary_test[doc_num][word]=1\n",
    "    doc_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0974de5-4a45-41d0-aa1c-c8a13b6bb144",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for k in dictionary_test.keys():\n",
    "    row = []\n",
    "    for f in features:\n",
    "        if(f in dictionary_test[k].keys()):\n",
    "            row.append(dictionary_test[k][f]) \n",
    "        else:\n",
    "            row.append(0)\n",
    "    X_test.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76cfe1ef-69b7-48b6-904a-a93969490bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a29042a0-ae16-463b-a77f-a7e446cc9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(X_train, y_train):\n",
    "    result = {\"TOTAL_DATA\":len(y_train)}\n",
    "    classes, counts = np.unique(y_train, return_counts=True)    \n",
    "    for i in range(len(classes)):\n",
    "        curr_class = classes[i]\n",
    "        result[curr_class] = {}\n",
    "        X_tr_curr = X_train[y_train == curr_class]\n",
    "        total_count=counts[i]\n",
    "        for j in range(X_train.shape[1]):\n",
    "            feature_name=features[j]\n",
    "            feature_sum=np.sum(X_tr_curr[:,j])\n",
    "            result[curr_class][feature_name] = feature_sum \n",
    "        result[curr_class][\"TOTAL_COUNT\"] = total_count\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccd8f6e8-db25-4737-b743-124afc08f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probablity(dictionary_train, x, curr_class):\n",
    "    output = np.log(dictionary_train[curr_class][\"TOTAL_COUNT\"]) - np.log(dictionary_train[\"TOTAL_DATA\"])\n",
    "    num_words = len(x)\n",
    "    for j in range(num_words):\n",
    "        if(x[j] in dictionary_train[curr_class].keys()):\n",
    "            xj = x[j]\n",
    "            count_curr_class_equal_xj = dictionary_train[curr_class][xj] + 1\n",
    "            count_curr_class = dictionary_train[curr_class][\"TOTAL_COUNT\"] + len(dictionary_train[curr_class].keys())\n",
    "            curr_xj_prob = np.log(count_curr_class_equal_xj) - np.log(count_curr_class)\n",
    "            output = output + curr_xj_prob\n",
    "        else:\n",
    "            continue \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "189423dd-81f6-4e3c-a0b0-5268ca531733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictunit(dictionary_train, x):\n",
    "    classes = dictionary_train.keys()\n",
    "    best_p = -10000\n",
    "    best_class = -1\n",
    "    for curr_class in classes:\n",
    "        if(curr_class == \"TOTAL_DATA\"):\n",
    "            continue\n",
    "        p_curr_class = probablity(dictionary_train, x, curr_class)\n",
    "        if(p_curr_class > best_p):\n",
    "            best_p = p_curr_class\n",
    "            best_class = curr_class\n",
    "            \n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39cda73c-db7b-41f7-ab58-8f5f5ae3f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary_train, X_test):\n",
    "    Y_pred = []\n",
    "    for x in X_test:\n",
    "        y_predicted = predictunit(dictionary_train, x)\n",
    "        Y_pred.append(y_predicted)\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7558f6a0-c0ca-4a7a-bfc6-7a1c46f5d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = naive_bayes_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9808a51-7db9-4757-b159-8995d57aee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "for key in dictionary_test.keys():\n",
    "    X_test.append(list(dictionary_test[key].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01b796c3-6e3e-4236-a60b-9d615e00badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92782913-0823-485f-8452-48fd6317fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.asarray(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5050a6e1-4651-44b5-8c17-75d6e594a823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5192519251925193"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41683024-7970-4839-bc38-3b89c63a3c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320   0   0   0   0   1   0   0   0   0   0   2   0   1   0  32   3  36\n",
      "   71  29]\n",
      " [  0 319   6   4   0  56   0   0   0   0   0  31   0   3   2   4   1  13\n",
      "   41   1]\n",
      " [  2  87  99  39   0 155   0   0   0   0   0  60   0   2   1   0   5   4\n",
      "   48   1]\n",
      " [  1  55  15 245   0  38   4   0   0   0   0  60   1   5   3   3   2   5\n",
      "   46   0]\n",
      " [  0  75  13  77  92  29   2   0   0   0   0  94   1   5   1   1   3  11\n",
      "   69   0]\n",
      " [  0  40   5   1   0 379   1   0   0   0   0  17   0   1   1   0   2   0\n",
      "   20   1]\n",
      " [  1  57  11  53   3  30 109  13   1   1   0  45   9   8   7   1   6  32\n",
      "  117   1]\n",
      " [  0   9   1   0   0   5   2 120   1   1   0  19   0   5  11   0  11  54\n",
      "  268   0]\n",
      " [  0   2   1   2   0   6   1   4 125   0   0  10   0   4   5   1  23  38\n",
      "  295   0]\n",
      " [  0   7   1   0   0   2   0   0   0 265  20   4   0   2   1   2  12  31\n",
      "  161   1]\n",
      " [  1   1   1   0   0   1   0   0   0   2 367   5   0   0   0   2   4   6\n",
      "  123   1]\n",
      " [  1   2   1   0   0   1   0   0   0   0   0 410   0   1   0   0   6   6\n",
      "   73   0]\n",
      " [  0  56   3  15   0  12   0   0   0   2   1 146  46  12  16   2  11  21\n",
      "  144   0]\n",
      " [  9   7   3   0   0   1   0   0   0   0   0  10   0 307   3  10   4  29\n",
      "  148   1]\n",
      " [  5  12   0   0   0   4   0   0   0   0   0  19   0   2 312   7   2  23\n",
      "  123   0]\n",
      " [  5   4   0   0   0   2   0   0   0   0   0   3   0   0   0 432   1  28\n",
      "   34   3]\n",
      " [  2   0   1   0   0   0   0   0   1   0   0   5   0   1   0   3 267  24\n",
      "  188   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   5   0   1   0   3   2 455\n",
      "   24   1]\n",
      " [  2   0   0   0   0   1   0   0   0   1   0   3   0   0   0   1  13  45\n",
      "  439   6]\n",
      " [123   1   0   0   0   2   0   0   0   0   0   4   0   0   2  91  21  35\n",
      "  146  84]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3a81f83-1351-4871-be63-b2c84ffeb7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.68      0.65      0.66       495\n",
      "           comp.graphics       0.43      0.66      0.53       481\n",
      " comp.os.ms-windows.misc       0.61      0.20      0.30       503\n",
      "comp.sys.ibm.pc.hardware       0.56      0.51      0.53       483\n",
      "   comp.sys.mac.hardware       0.97      0.19      0.32       473\n",
      "          comp.windows.x       0.52      0.81      0.64       468\n",
      "            misc.forsale       0.92      0.22      0.35       505\n",
      "               rec.autos       0.88      0.24      0.37       507\n",
      "         rec.motorcycles       0.98      0.24      0.39       517\n",
      "      rec.sport.baseball       0.97      0.52      0.68       509\n",
      "        rec.sport.hockey       0.95      0.71      0.81       514\n",
      "               sci.crypt       0.43      0.82      0.56       501\n",
      "         sci.electronics       0.81      0.09      0.17       487\n",
      "                 sci.med       0.85      0.58      0.69       532\n",
      "               sci.space       0.85      0.61      0.71       509\n",
      "  soc.religion.christian       0.73      0.84      0.78       512\n",
      "      talk.politics.guns       0.67      0.54      0.60       492\n",
      "   talk.politics.mideast       0.51      0.93      0.66       491\n",
      "      talk.politics.misc       0.17      0.86      0.28       511\n",
      "      talk.religion.misc       0.65      0.17      0.26       509\n",
      "\n",
      "                accuracy                           0.52      9999\n",
      "               macro avg       0.71      0.52      0.51      9999\n",
      "            weighted avg       0.71      0.52      0.52      9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5416ab3-ca61-4501-9cba-96340b0e0e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
